{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJRDh8AlPKH4n3HNr9HosR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Here's a comprehensive list of **Keras classes, functions, and modules** used for building **Artificial Neural Networks (ANNs)**:\n","\n","---\n","\n","## 🔹 1. **Modules in Keras for ANN**\n","\n","```python\n","from tensorflow import keras\n","from tensorflow.keras import layers, models, optimizers, losses, metrics, initializers, callbacks\n","```\n","\n","---\n","\n","## 🔹 2. **Core ANN Classes and Functions**\n","\n","### ✅ **Model Building**\n","\n","* `keras.models.Sequential()`\n","* `keras.models.Model()` *(for Functional API)*\n","\n","### ✅ **Layers (Common for ANN)**\n","\n","* `layers.Dense()` – Fully connected layer\n","* `layers.Dropout()` – Dropout regularization\n","* `layers.BatchNormalization()` – Batch normalization\n","* `layers.Activation()` – Apply activation function\n","* `layers.Input()` – Input layer (used in Functional API)\n","* `layers.Flatten()` – Flattens input\n","\n","---\n","\n","## 🔹 3. **Activation Functions**\n","\n","* `\"relu\"` – Rectified Linear Unit\n","* `\"sigmoid\"` – Sigmoid activation\n","* `\"tanh\"` – Hyperbolic tangent\n","* `\"softmax\"` – Used for multi-class classification\n","* `\"linear\"` – No activation\n","\n","> You can also use `keras.activations` directly:\n","\n","```python\n","keras.activations.relu, sigmoid, softmax, tanh, linear\n","```\n","\n","---\n","\n","## 🔹 4. **Loss Functions**\n","\n","* `losses.MeanSquaredError()` or `'mse'`\n","* `losses.MeanAbsoluteError()` or `'mae'`\n","* `losses.BinaryCrossentropy()` or `'binary_crossentropy'`\n","* `losses.CategoricalCrossentropy()` or `'categorical_crossentropy'`\n","* `losses.SparseCategoricalCrossentropy()`\n","\n","---\n","\n","## 🔹 5. **Optimizers**\n","\n","* `optimizers.SGD()`\n","* `optimizers.Adam()`\n","* `optimizers.RMSprop()`\n","* `optimizers.Adagrad()`\n","* `optimizers.Adamax()`\n","* `optimizers.Nadam()`\n","\n","---\n","\n","## 🔹 6. **Metrics**\n","\n","* `metrics.Accuracy()`\n","* `metrics.BinaryAccuracy()`\n","* `metrics.CategoricalAccuracy()`\n","* `metrics.AUC()`\n","* `metrics.MeanAbsoluteError()`\n","* `'accuracy'`, `'mae'`, `'mse'`, etc.\n","\n","---\n","\n","## 🔹 7. **Model Compilation & Training**\n","\n","* `.compile(optimizer, loss, metrics)`\n","* `.fit(X, y, epochs=..., batch_size=...)`\n","* `.evaluate(X_test, y_test)`\n","* `.predict(X_input)`\n","\n","---\n","\n","## 🔹 8. **Callbacks**\n","\n","* `callbacks.EarlyStopping()`\n","* `callbacks.ModelCheckpoint()`\n","* `callbacks.TensorBoard()`\n","* `callbacks.ReduceLROnPlateau()`\n","\n","---\n","\n","## 🔹 9. **Initializers**\n","\n","Used to initialize weights of layers:\n","\n","* `initializers.Zeros()`\n","* `initializers.Ones()`\n","* `initializers.RandomNormal()`\n","* `initializers.HeNormal()` *(Good for ReLU)*\n","* `initializers.GlorotUniform()` *(Xavier init)*\n","\n","---\n","\n","## 🔹 10. **Utilities**\n","\n","* `keras.utils.to_categorical()` – Converts class vectors to binary class matrix\n","* `keras.utils.plot_model()` – Visualize model architecture\n","\n","---\n","\n","### 🔸 Example of ANN using `Sequential` API:\n","\n","```python\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(10,)),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=20, batch_size=32)\n","```\n","\n","---\n","\n","Would you like the **same list as a PDF or visual diagram**?\n"],"metadata":{"id":"ElxBsSEP-NXe"}},{"cell_type":"markdown","source":["Here’s a comprehensive list of key **Keras classes, functions, and modules** used for building **Artificial Neural Networks (ANNs)** in TensorFlow (as of **TensorFlow 2.x**):\n","\n","---\n","\n","### **1. Core Layers (Building Blocks of ANN)**\n","- **`Dense`** – Fully connected layer (`tf.keras.layers.Dense`).\n","- **`Input`** – Defines input layer/specification (`tf.keras.Input`).\n","- **`Flatten`** – Flattens input (e.g., for CNN → Dense transition).\n","- **`Dropout`** – Regularization by randomly dropping units (`tf.keras.layers.Dropout`).\n","- **`BatchNormalization`** – Normalizes activations for stable training.\n","\n","---\n","\n","### **2. Activation Functions**\n","- **`activations`** module (`tf.keras.activations`):\n","  - `relu`, `sigmoid`, `softmax`, `tanh`, `leaky_relu`, `elu`, `selu`, `swish`.\n","- **Usage in layers**:  \n","  ```python\n","  Dense(64, activation='relu')  \n","  ```\n","\n","---\n","\n","### **3. Model Classes**\n","- **`Sequential`** – Linear stack of layers (`tf.keras.Sequential`).\n","- **`Model`** – Functional API for complex architectures (`tf.keras.Model`).\n","- **`Subclassing`** – Custom models via `tf.keras.Model` subclassing.\n","\n","---\n","\n","### **4. Loss Functions (`tf.keras.losses`)**\n","- **Regression**: `MeanSquaredError` (MSE), `MeanAbsoluteError` (MAE).\n","- **Classification**:  \n","  - `BinaryCrossentropy` (for binary classification),  \n","  - `CategoricalCrossentropy` (multi-class),  \n","  - `SparseCategoricalCrossentropy` (integer labels).  \n","- **Custom Loss**: Define a function and pass it to `model.compile()`.\n","\n","---\n","\n","### **5. Optimizers (`tf.keras.optimizers`)**\n","- **`SGD`** – Stochastic Gradient Descent (with momentum support).\n","- **`Adam`**, `AdamW` – Adaptive momentum-based optimizer.\n","- **`RMSprop`** – Root Mean Square Propagation.\n","- **`Adagrad`**, `Adadelta`, `Nadam` – Other adaptive optimizers.\n","\n","---\n","\n","### **6. Metrics (`tf.keras.metrics`)**\n","- **`Accuracy`**, `BinaryAccuracy`, `CategoricalAccuracy`.\n","- **`Precision`**, `Recall`, `AUC` (for imbalanced data).\n","- **`MeanSquaredError`**, `MeanAbsoluteError` (regression).\n","- Custom metrics via subclassing `tf.keras.metrics.Metric`.\n","\n","---\n","\n","### **7. Initializers (`tf.keras.initializers`)**\n","- **`HeNormal`**, `HeUniform` – For ReLU activations.\n","- **`GlorotNormal`**, `GlorotUniform` (Xavier initialization).\n","- **`RandomNormal`**, `RandomUniform`, `Zeros`, `Ones`.\n","\n","---\n","\n","### **8. Regularizers (`tf.keras.regularizers`)**\n","- **`L1`**, `L2` – L1/L2 weight regularization.\n","- **`L1L2`** – Combined L1 + L2.\n","- Used in layers:  \n","  ```python\n","  Dense(64, kernel_regularizer=l2(0.01))\n","  ```\n","\n","---\n","\n","### **9. Callbacks (`tf.keras.callbacks`)**\n","- **`EarlyStopping`** – Stops training if no improvement.\n","- **`ModelCheckpoint`** – Saves model weights.\n","- **`TensorBoard`** – Logs for visualization.\n","- **`LearningRateScheduler`** – Adjusts LR dynamically.\n","- **`CSVLogger`** – Saves training history to CSV.\n","\n","---\n","\n","### **10. Data Preprocessing & Utilities**\n","- **`tf.keras.utils.to_categorical`** – One-hot encodes labels.\n","- **`tf.keras.utils.normalize`** – Normalizes data.\n","- **`tf.keras.preprocessing.sequence`** – For time-series data.\n","- **`tf.keras.preprocessing.image.ImageDataGenerator`** – Augmentation (though prefer `tf.data` in modern TF).\n","\n","---\n","\n","### **11. Training & Evaluation**\n","- **`model.compile()`** – Configures optimizer, loss, metrics.\n","- **`model.fit()`** – Trains the model.\n","- **`model.evaluate()`** – Evaluates on test data.\n","- **`model.predict()`** – Generates predictions.\n","- **`model.save()`** / **`tf.keras.models.load_model()`** – Saves/loads models.\n","\n","---\n","\n","### **12. Advanced Layers (Beyond Simple ANN)**\n","- **Embedding** – For categorical data (`tf.keras.layers.Embedding`).\n","- **RNN/LSTM/GRU** – Recurrent layers (though typically for sequences).\n","- **Conv1D/2D/3D** – Convolutional layers (for CNNs).\n","\n","---\n","\n","### **Example Code Snippet:**\n","```python\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(input_dim,)),\n","    Dropout(0.2),\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='sigmoid')  # Binary classification\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n","```\n","\n","---\n","\n","### **Where to Find Documentation?**\n","- Official Docs: [https://keras.io/api/](https://keras.io/api/)  \n","- TensorFlow Keras: [https://www.tensorflow.org/api_docs/python/tf/keras](https://www.tensorflow.org/api_docs/python/tf/keras)\n","\n","This list covers the essentials for **ANNs** (MLPs). For CNNs/RNNs, additional layers are used. Let me know if you need details on a specific topic!"],"metadata":{"id":"n7JyAWdy-J1L"}},{"cell_type":"code","source":[],"metadata":{"id":"FIZu9oeN-Kwd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sure! I’ll give you a **comprehensive list of TensorFlow functions and methods** with **concise 2-line explanations**. I’ll structure it by coverage: **80% (common real-world usage), 90% (advanced), 100% (rare or specialized)**.\n","\n","---\n","\n","## **TensorFlow Functions & Methods — 80% Real-World Usage**\n","\n","### **Core Tensor Operations**\n","\n","* `tf.constant(value)` → Creates a constant tensor from a given value.\n","* `tf.Variable(initial_value)` → Creates a mutable tensor (variable) that can be updated during training.\n","* `tf.zeros(shape)` → Creates a tensor filled with zeros of specified shape.\n","* `tf.ones(shape)` → Creates a tensor filled with ones.\n","* `tf.reshape(tensor, shape)` → Reshapes a tensor to a new shape without changing data.\n","* `tf.transpose(tensor, perm)` → Permutes the dimensions of a tensor.\n","* `tf.squeeze(tensor)` → Removes dimensions of size 1.\n","* `tf.expand_dims(tensor, axis)` → Adds a new dimension at the specified axis.\n","* `tf.cast(tensor, dtype)` → Changes the data type of a tensor.\n","\n","### **Mathematical Operations**\n","\n","* `tf.add(a, b)` → Element-wise addition of tensors.\n","* `tf.subtract(a, b)` → Element-wise subtraction.\n","* `tf.multiply(a, b)` → Element-wise multiplication.\n","* `tf.divide(a, b)` → Element-wise division.\n","* `tf.matmul(a, b)` → Matrix multiplication for 2D or higher tensors.\n","* `tf.reduce_sum(tensor, axis)` → Sums elements across specified axes.\n","* `tf.reduce_mean(tensor, axis)` → Computes mean across specified axes.\n","* `tf.reduce_max(tensor, axis)` → Computes maximum across axes.\n","* `tf.argmax(tensor, axis)` → Returns index of maximum value along axis.\n","* `tf.argmin(tensor, axis)` → Returns index of minimum value along axis.\n","\n","### **Neural Network Layers & Activation**\n","\n","* `tf.keras.layers.Dense(units, activation)` → Fully connected layer.\n","* `tf.keras.layers.Conv2D(filters, kernel_size)` → 2D convolution layer for images.\n","* `tf.keras.layers.MaxPooling2D(pool_size)` → Downsamples input using max pooling.\n","* `tf.keras.layers.Flatten()` → Flattens input to 1D tensor.\n","* `tf.keras.layers.Dropout(rate)` → Randomly sets input units to 0 during training.\n","* `tf.nn.relu(x)` → Applies ReLU activation.\n","* `tf.nn.sigmoid(x)` → Sigmoid activation function.\n","* `tf.nn.softmax(x)` → Softmax function for classification probabilities.\n","\n","### **Model & Training Utilities**\n","\n","* `tf.keras.Sequential(layers)` → Defines a sequential model.\n","* `tf.keras.Model(inputs, outputs)` → Functional API model definition.\n","* `model.compile(optimizer, loss, metrics)` → Prepares the model for training.\n","* `model.fit(x, y, epochs, batch_size)` → Trains the model.\n","* `model.evaluate(x, y)` → Evaluates model performance.\n","* `model.predict(x)` → Generates predictions.\n","\n","### **Data & Dataset**\n","\n","* `tf.data.Dataset.from_tensor_slices(data)` → Creates a dataset from tensors.\n","* `dataset.batch(batch_size)` → Batches the dataset.\n","* `dataset.shuffle(buffer_size)` → Shuffles dataset for training.\n","* `dataset.map(map_func)` → Applies a function to each dataset element.\n","\n","---\n","\n","## **90% Coverage — Advanced / Specialized**\n","\n","* `tf.image.resize(images, size)` → Resizes images to a new size.\n","* `tf.image.random_flip_left_right(image)` → Randomly flips image horizontally.\n","* `tf.image.random_brightness(image, max_delta)` → Adjusts brightness randomly.\n","* `tf.linalg.inv(matrix)` → Computes inverse of a square matrix.\n","* `tf.linalg.det(matrix)` → Computes determinant.\n","* `tf.GradientTape()` → Records operations for automatic differentiation.\n","* `tape.gradient(loss, variables)` → Computes gradients of `loss` w\\.r.t `variables`.\n","* `tf.function` → Compiles Python function into TensorFlow graph for performance.\n","* `tf.keras.callbacks.EarlyStopping()` → Stops training when a monitored metric stops improving.\n","* `tf.keras.callbacks.ModelCheckpoint()` → Saves model during training.\n","\n","---\n","\n","## **100% Coverage — Rare / Edge Use**\n","\n","* `tf.raw_ops` → Access low-level TensorFlow operations not exposed in high-level API.\n","* `tf.experimental.numpy` → Use NumPy-like functions in TensorFlow graph.\n","* `tf.debugging.assert_equal(x, y)` → Checks equality and raises errors for debugging.\n","* `tf.data.experimental.prefetch_to_device(device)` → Prefetch dataset to a device.\n","* `tf.distribute.Strategy` → Enables distributed training across GPUs/TPUs.\n","* `tf.function(input_signature=...)` → Advanced graph tracing with strict input shapes.\n","* `tf.keras.mixed_precision.set_global_policy('mixed_float16')` → Enables mixed precision training.\n","* `tf.summary.create_file_writer(logdir)` → Logs metrics for TensorBoard visualization.\n","* `tf.signal.stft()` → Short-time Fourier Transform for audio processing.\n","\n","---\n","\n","✅ This structure covers **80% of real-world usage**, **90% advanced**, and **100% specialized functions**.\n","\n"],"metadata":{"id":"qsITyNv8S5Ba"}},{"cell_type":"code","source":[],"metadata":{"id":"I9R1tzQtS4gi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sure! Let’s break it down simply and clearly.\n","\n","---\n","\n","## **Tensor — Simple Definition**\n","\n","A **tensor** is a **multi-dimensional array** (like a vector or matrix) that **stores data** in TensorFlow.\n","\n","* **0D Tensor:** Single number (scalar) → e.g., `5`\n","* **1D Tensor:** Vector → e.g., `[1, 2, 3]`\n","* **2D Tensor:** Matrix → e.g., `[[1,2],[3,4]]`\n","* **3D Tensor:** e.g., a color image → `[height, width, channels]`\n","* **ND Tensor:** Any higher dimensions for complex data like videos or batches.\n","\n","---\n","\n","## **TensorFlow Sub-versions / Variants**\n","\n","1. **TensorFlow (Standard)**\n","\n","   * Full-featured TensorFlow library for **training and deploying ML/DL models** on CPU/GPU/TPU.\n","\n","2. **TensorFlow Lite (TFLite)**\n","\n","   * Lightweight version of TensorFlow for **mobile and embedded devices**.\n","   * Optimized for **fast inference** and **small binary size**.\n","\n","3. **TensorFlow\\.js**\n","\n","   * TensorFlow **for JavaScript**, runs **in browser** or **Node.js**.\n","   * Useful for **web-based ML applications**.\n","\n","4. **TensorFlow Extended (TFX)**\n","\n","   * End-to-end platform for **production ML pipelines**.\n","   * Handles **data preprocessing, training, evaluation, deployment**.\n","\n","5. **TensorFlow Hub**\n","\n","   * Repository of **pre-trained models** that can be reused in your projects.\n","\n","6. **TensorFlow Probability (TFP)**\n","\n","   * For **probabilistic modeling, Bayesian statistics**, and uncertainty estimation.\n","\n","7. **TensorFlow Federated (TFF)**\n","\n","   * Framework for **federated learning**, trains models **across decentralized devices** without sharing raw data.\n","\n","8. **TensorFlow Quantum (TFQ)**\n","\n","   * Integrates **quantum computing** with TensorFlow for hybrid ML + quantum models.\n","\n","---\n","\n","If you want, I can **draw a simple diagram showing Tensor → TensorFlow → TensorFlow Lite / JS / TFX**, which makes it super easy to remember.\n","\n","Do you want me to make that diagram?\n"],"metadata":{"id":"EKJ5KDUDS-Z7"}},{"cell_type":"code","source":[],"metadata":{"id":"ZzS6pzOlS-q8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Sure! When you say **“all types of code reference program”**, I assume you want a **collection of small, ready-to-use TensorFlow code snippets** that cover **common real-world scenarios**—training, inference, data preprocessing, layers, activation, saving models, and advanced features. I’ll structure them clearly.\n","\n","---\n","\n","# **TensorFlow Code Reference Programs**\n","\n","## **1. Basic Tensor Creation**\n","\n","```python\n","import tensorflow as tf\n","\n","# Scalar (0D)\n","scalar = tf.constant(5)\n","\n","# Vector (1D)\n","vector = tf.constant([1,2,3])\n","\n","# Matrix (2D)\n","matrix = tf.constant([[1,2],[3,4]])\n","\n","# 3D Tensor (e.g., image)\n","tensor3d = tf.zeros([32, 32, 3])  # 32x32 RGB image\n","```\n","\n","---\n","\n","## **2. Tensor Operations**\n","\n","```python\n","a = tf.constant([1,2,3])\n","b = tf.constant([4,5,6])\n","\n","add = tf.add(a, b)         # Element-wise addition\n","mul = tf.multiply(a, b)    # Element-wise multiplication\n","matmul = tf.matmul([[1,2],[3,4]], [[5,6],[7,8]])  # Matrix multiplication\n","reshape = tf.reshape(a, [3,1])\n","```\n","\n","---\n","\n","## **3. Neural Network Layers**\n","\n","```python\n","from tensorflow.keras import layers\n","\n","# Fully connected layer\n","dense = layers.Dense(10, activation='relu')\n","\n","# Conv2D layer\n","conv = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n","\n","# Flatten and Dropout\n","flatten = layers.Flatten()\n","dropout = layers.Dropout(0.5)\n","```\n","\n","---\n","\n","## **4. Build Sequential Model**\n","\n","```python\n","from tensorflow.keras.models import Sequential\n","\n","model = Sequential([\n","    layers.Flatten(input_shape=(28,28)),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.2),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","```\n","\n","---\n","\n","## **5. Train & Evaluate**\n","\n","```python\n","# Example dataset: MNIST\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train/255.0, x_test/255.0  # Normalize\n","\n","# Train model\n","model.fit(x_train, y_train, epochs=5, batch_size=32)\n","\n","# Evaluate model\n","loss, acc = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", acc)\n","```\n","\n","---\n","\n","## **6. Model Prediction**\n","\n","```python\n","predictions = model.predict(x_test[:5])\n","print(predictions.argmax(axis=1))  # Predicted labels\n","```\n","\n","---\n","\n","## **7. Dataset & Preprocessing**\n","\n","```python\n","# Using tf.data API\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","dataset = dataset.shuffle(10000).batch(32)\n","\n","# Mapping function\n","def normalize(x, y):\n","    x = tf.cast(x, tf.float32)/255.0\n","    return x, y\n","\n","dataset = dataset.map(normalize)\n","```\n","\n","---\n","\n","## **8. Using GradientTape (Custom Training)**\n","\n","```python\n","x = tf.constant([[1.0, 2.0]])\n","y_true = tf.constant([[0.0]])\n","\n","w = tf.Variable([[0.1],[0.2]])\n","b = tf.Variable([0.0])\n","\n","with tf.GradientTape() as tape:\n","    y_pred = tf.matmul(x, w) + b\n","    loss = tf.reduce_mean((y_true - y_pred)**2)\n","\n","grad = tape.gradient(loss, [w, b])\n","w.assign_sub(0.01 * grad[0])\n","b.assign_sub(0.01 * grad[1])\n","```\n","\n","---\n","\n","## **9. Saving & Loading Models**\n","\n","```python\n","# Save model\n","model.save('my_model.h5')\n","\n","# Load model\n","new_model = tf.keras.models.load_model('my_model.h5')\n","```\n","\n","---\n","\n","## **10. TensorFlow Lite Conversion**\n","\n","```python\n","# Convert Keras model to TFLite\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# Save TFLite model\n","with open(\"model.tflite\", \"wb\") as f:\n","    f.write(tflite_model)\n","```\n","\n","---\n","\n","## **11. Callbacks Example**\n","\n","```python\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=3),\n","    ModelCheckpoint('best_model.h5', save_best_only=True)\n","]\n","\n","model.fit(x_train, y_train, validation_split=0.2, epochs=10, callbacks=callbacks)\n","```\n","\n","---\n","\n","## **12. Advanced: Mixed Precision**\n","\n","```python\n","from tensorflow.keras import mixed_precision\n","\n","mixed_precision.set_global_policy('mixed_float16')\n","```\n","\n","---\n","\n","## **13. TensorFlow Probability Example**\n","\n","```python\n","import tensorflow_probability as tfp\n","\n","dist = tfp.distributions.Normal(loc=0., scale=1.)\n","sample = dist.sample(5)\n","print(sample)\n","```\n","\n","---\n","\n","✅ This **covers 80–90% of real-world TensorFlow code references**.\n","\n","I can also make a **“100% Ultimate TensorFlow Reference Sheet”** with **all possible small code snippets including image, NLP, sequence models, GANs, RNN/LSTM/Transformer examples** for real-world usage if you want.\n","\n","Do you want me to make that full 100% version next?\n"],"metadata":{"id":"MSunlBJPTWpN"}},{"cell_type":"code","source":[],"metadata":{"id":"_ek7q_G2TaxO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perfect! Here’s a **100% Ultimate TensorFlow Reference Sheet**—all the important **code snippets, operations, and practical examples** you’ll need in one place. I’ll structure it in **categories**: Core, Layers, Models, Data, Training, Advanced, and Deployment.\n","\n","---\n","\n","# **100% Ultimate TensorFlow Reference Sheet**\n","\n","---\n","\n","## **1. Core Tensor Operations**\n","\n","```python\n","import tensorflow as tf\n","\n","# Tensor Creation\n","scalar = tf.constant(5)\n","vector = tf.constant([1,2,3])\n","matrix = tf.constant([[1,2],[3,4]])\n","zeros = tf.zeros([3,3])\n","ones = tf.ones([2,2])\n","random = tf.random.normal([2,2])\n","\n","# Reshape / Transpose\n","reshaped = tf.reshape(matrix, [4,1])\n","transposed = tf.transpose(matrix)\n","expanded = tf.expand_dims(vector, axis=0)\n","squeezed = tf.squeeze(expanded)\n","casted = tf.cast(vector, tf.float32)\n","\n","# Math Operations\n","a = tf.constant([1,2,3])\n","b = tf.constant([4,5,6])\n","add = tf.add(a,b)\n","sub = tf.subtract(a,b)\n","mul = tf.multiply(a,b)\n","div = tf.divide(a,b)\n","matmul = tf.matmul([[1,2],[3,4]], [[5,6],[7,8]])\n","reduce_sum = tf.reduce_sum(matrix)\n","reduce_mean = tf.reduce_mean(matrix)\n","argmax = tf.argmax(a)\n","argmin = tf.argmin(a)\n","```\n","\n","---\n","\n","## **2. Activation Functions**\n","\n","```python\n","x = tf.constant([-1.0, 0.0, 1.0])\n","relu = tf.nn.relu(x)\n","sigmoid = tf.nn.sigmoid(x)\n","softmax = tf.nn.softmax([x,x])\n","tanh = tf.nn.tanh(x)\n","leaky_relu = tf.nn.leaky_relu(x)\n","```\n","\n","---\n","\n","## **3. Layers**\n","\n","```python\n","from tensorflow.keras import layers\n","\n","# Dense / Fully Connected\n","dense = layers.Dense(128, activation='relu')\n","\n","# Convolution\n","conv2d = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n","maxpool = layers.MaxPooling2D(pool_size=(2,2))\n","flatten = layers.Flatten()\n","dropout = layers.Dropout(0.5)\n","embedding = layers.Embedding(input_dim=1000, output_dim=64)\n","\n","# Recurrent Layers\n","lstm = layers.LSTM(64)\n","gru = layers.GRU(64)\n","rnn = layers.SimpleRNN(32)\n","```\n","\n","---\n","\n","## **4. Models**\n","\n","```python\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras import Input\n","\n","# Sequential API\n","model = Sequential([\n","    layers.Flatten(input_shape=(28,28)),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.2),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# Functional API\n","inputs = Input(shape=(28,28))\n","x = layers.Flatten()(inputs)\n","x = layers.Dense(128, activation='relu')(x)\n","outputs = layers.Dense(10, activation='softmax')(x)\n","func_model = Model(inputs, outputs)\n","\n","# Compile\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","```\n","\n","---\n","\n","## **5. Data Handling**\n","\n","```python\n","# Load dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train/255.0, x_test/255.0\n","\n","# tf.data API\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","dataset = dataset.shuffle(10000).batch(32)\n","dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), y))\n","\n","# Image preprocessing\n","image = tf.random.normal([256,256,3])\n","resized = tf.image.resize(image, [128,128])\n","flipped = tf.image.random_flip_left_right(resized)\n","bright = tf.image.random_brightness(flipped, max_delta=0.2)\n","```\n","\n","---\n","\n","## **6. Training & Evaluation**\n","\n","```python\n","# Fit model\n","model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n","\n","# Evaluate\n","loss, acc = model.evaluate(x_test, y_test)\n","\n","# Predict\n","preds = model.predict(x_test[:5])\n","pred_labels = tf.argmax(preds, axis=1)\n","```\n","\n","---\n","\n","## **7. Callbacks**\n","\n","```python\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=3)\n","checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n","tensorboard = TensorBoard(log_dir='./logs')\n","\n","model.fit(x_train, y_train, epochs=20, validation_split=0.2, callbacks=[early_stop, checkpoint, tensorboard])\n","```\n","\n","---\n","\n","## **8. Custom Training with GradientTape**\n","\n","```python\n","x = tf.constant([[1.0,2.0]])\n","y_true = tf.constant([[0.0]])\n","\n","w = tf.Variable([[0.1],[0.2]])\n","b = tf.Variable([0.0])\n","\n","with tf.GradientTape() as tape:\n","    y_pred = tf.matmul(x, w) + b\n","    loss = tf.reduce_mean((y_true - y_pred)**2)\n","\n","grad = tape.gradient(loss, [w, b])\n","w.assign_sub(0.01 * grad[0])\n","b.assign_sub(0.01 * grad[1])\n","```\n","\n","---\n","\n","## **9. TensorFlow Lite Conversion**\n","\n","```python\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","with open(\"model.tflite\", \"wb\") as f:\n","    f.write(tflite_model)\n","```\n","\n","---\n","\n","## **10. Distributed Training**\n","\n","```python\n","strategy = tf.distribute.MirroredStrategy()  # Multi-GPU\n","with strategy.scope():\n","    dist_model = Sequential([\n","        layers.Dense(128, activation='relu', input_shape=(28,28)),\n","        layers.Dense(10, activation='softmax')\n","    ])\n","    dist_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","```\n","\n","---\n","\n","## **11. Mixed Precision**\n","\n","```python\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy('mixed_float16')\n","```\n","\n","---\n","\n","## **12. TensorFlow Probability**\n","\n","```python\n","import tensorflow_probability as tfp\n","dist = tfp.distributions.Normal(loc=0., scale=1.)\n","samples = dist.sample(5)\n","log_prob = dist.log_prob(samples)\n","```\n","\n","---\n","\n","## **13. NLP Example (Embedding + LSTM)**\n","\n","```python\n","vocab_size = 1000\n","embed_dim = 64\n","seq_len = 50\n","\n","model_nlp = Sequential([\n","    layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=seq_len),\n","    layers.LSTM(128),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","model_nlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","```\n","\n","---\n","\n","## **14. Image Classification Example**\n","\n","```python\n","from tensorflow.keras.applications import MobileNetV2\n","\n","base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n","base_model.trainable = False\n","\n","inputs = Input(shape=(224,224,3))\n","x = base_model(inputs, training=False)\n","x = layers.GlobalAveragePooling2D()(x)\n","outputs = layers.Dense(10, activation='softmax')(x)\n","img_model = Model(inputs, outputs)\n","img_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","```\n","\n","---\n","\n","## **15. Audio Processing Example**\n","\n","```python\n","# Short-time Fourier Transform (STFT)\n","audio = tf.random.normal([16000])\n","stft = tf.signal.stft(audio, frame_length=256, frame_step=128)\n","magnitude = tf.abs(stft)\n","```\n","\n","---\n","\n","## ✅ Notes\n","\n","* Covers **all practical real-world scenarios**: **core ops, layers, models, data, training, deployment**.\n","* Includes **Advanced features**: GradientTape, TFLite, Distributed, Mixed Precision, Probability, NLP, Image, Audio.\n","\n","---\n","\n","If you want, I can **convert this into a visually clean PDF cheat sheet** with **columns: Category | Function | Example | Notes**—perfect for **interviews and quick reference**.\n","\n","Do you want me to make that PDF?\n"],"metadata":{"id":"__9bcX1RTbaR"}},{"cell_type":"code","source":[],"metadata":{"id":"fPeqbIJRTbom"},"execution_count":null,"outputs":[]}]}