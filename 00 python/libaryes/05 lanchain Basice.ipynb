{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnb3bGyhthmszZw1dX6Bhz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Ah! You want a **master-level reference for LangChain**, including its **core concepts, modules, functions, and coding patterns**. I’ll give a structured, concise, yet thorough overview suitable for practical use and interviews.\n","\n","---\n","\n","# **LangChain Ultimate Reference (Master Level)**\n","\n","LangChain is a **framework for building applications with LLMs**, focusing on modularity: LLMs, prompts, memory, chains, and agents.\n","\n","---\n","\n","## **1️⃣ Core Concepts**\n","\n","| Concept                  | Description                                                       |\n","| ------------------------ | ----------------------------------------------------------------- |\n","| **LLM (Language Model)** | Interface to any LLM (OpenAI, HuggingFace, Azure, etc.).          |\n","| **Prompt**               | Template for model input, can include variables.                  |\n","| **Chain**                | Sequence of calls (LLM, tools, or transformations).               |\n","| **Agent**                | Decision-making system that can choose tools/actions dynamically. |\n","| **Memory**               | Stores conversational context across calls.                       |\n","| **Tool**                 | Callable function for the agent (e.g., search, calculator).       |\n","\n","---\n","\n","## **2️⃣ Installation**\n","\n","```bash\n","pip install langchain openai chromadb\n","```\n","\n","Optional for embeddings & vector stores:\n","\n","```bash\n","pip install faiss-cpu\n","```\n","\n","---\n","\n","## **3️⃣ LLM Wrappers**\n","\n","```python\n","from langchain.llms import OpenAI\n","\n","# Initialize OpenAI LLM\n","llm = OpenAI(model_name=\"gpt-4\", temperature=0.7)\n","\n","# Generate response\n","output = llm(\"Explain LangChain in simple words\")\n","print(output)\n","```\n","\n","Other LLMs: `ChatOpenAI`, `HuggingFaceHub`, `Cohere`, `AzureChatOpenAI`.\n","\n","---\n","\n","## **4️⃣ Prompts & Prompt Templates**\n","\n","```python\n","from langchain.prompts import PromptTemplate\n","\n","# Create a template\n","template = \"Translate this text to French: {text}\"\n","prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n","\n","# Generate LLM output\n","output = llm(prompt.format(text=\"Hello, how are you?\"))\n","print(output)\n","```\n","\n","Advanced features:\n","\n","* `FewShotPromptTemplate` for few-shot learning.\n","* `ChatPromptTemplate` for multi-turn chat inputs.\n","\n","---\n","\n","## **5️⃣ Chains**\n","\n","Chains **connect multiple components**:\n","\n","```python\n","from langchain.chains import LLMChain\n","\n","# Create a chain with LLM and prompt\n","chain = LLMChain(llm=llm, prompt=prompt)\n","result = chain.run(\"I am learning LangChain\")\n","print(result)\n","```\n","\n","Other chain types:\n","\n","* `SequentialChain` – Run multiple chains sequentially.\n","* `SimpleSequentialChain` – Easy single-input sequential execution.\n","* `TransformChain` – Apply a transformation function.\n","\n","---\n","\n","## **6️⃣ Agents**\n","\n","Agents **decide which tool or action to use dynamically**:\n","\n","```python\n","from langchain.agents import initialize_agent, Tool\n","from langchain.agents import AgentType\n","\n","# Define a tool\n","def calculator(input: str) -> str:\n","    return str(eval(input))\n","\n","tools = [Tool(name=\"Calculator\", func=calculator, description=\"Evaluate math expressions\")]\n","\n","# Initialize agent\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","\n","# Run agent\n","agent.run(\"What is 45 * 32?\")\n","```\n","\n","Agent types:\n","\n","* `ZERO_SHOT_REACT_DESCRIPTION` – Decide action based on description.\n","* `CONVERSATIONAL_REACT_DESCRIPTION` – Use with memory for chat.\n","* `PLAN_AND_EXECUTE` – Plan complex multi-step actions.\n","\n","---\n","\n","## **7️⃣ Memory**\n","\n","Memory **remembers conversation context**:\n","\n","```python\n","from langchain.memory import ConversationBufferMemory\n","from langchain.chains import ConversationChain\n","\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n","\n","conversation.run(\"Hello!\")\n","conversation.run(\"Who are you?\")\n","```\n","\n","Other memory types:\n","\n","* `ConversationSummaryMemory` – Summarizes conversation to save tokens.\n","* `VectorStoreRetrieverMemory` – Stores conversation in vector DB.\n","\n","---\n","\n","## **8️⃣ Tools & Integrations**\n","\n","* Web search: `SerpAPIWrapper`, `GoogleSearchAPIWrapper`\n","* Wikipedia: `WikipediaAPIWrapper`\n","* File / DB: `SQLDatabase`, `Chroma`, `FAISS`\n","* Custom tools: Any callable Python function.\n","\n","```python\n","from langchain.tools import Tool\n","\n","def greet(name: str) -> str:\n","    return f\"Hello, {name}!\"\n","\n","tool = Tool(name=\"GreetTool\", func=greet, description=\"Say hello to someone\")\n","```\n","\n","---\n","\n","## **9️⃣ Vector Stores & Retrieval (RAG)**\n","\n","```python\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Embeddings\n","embeddings = OpenAIEmbeddings()\n","\n","# Initialize vector store\n","vectordb = Chroma(persist_directory=\"db\", embedding_function=embeddings)\n","\n","# Add documents\n","docs = [\"LangChain is awesome!\", \"RAG allows retrieval + LLM.\"]\n","vectordb.add_texts(docs)\n","\n","# Query\n","results = vectordb.similarity_search(\"Tell me about RAG\")\n","print(results)\n","```\n","\n","---\n","\n","## **10️⃣ Common Workflows**\n","\n","1. **Simple Prompt → LLM → Output**\n","2. **LLMChain with Prompt → Output**\n","3. **Conversation with Memory**\n","4. **Agent using Tools**\n","5. **RAG (Retrieval-Augmented Generation)**\n","6. **Multi-step Sequential Chains**\n","\n","---\n","\n","## **11️⃣ Tips & Best Practices**\n","\n","* Always use **PromptTemplate** for clean and reusable prompts.\n","* Use **memory** for conversational agents.\n","* For large datasets, use **vector stores** (Chroma, FAISS) with embeddings.\n","* Use **agents** for dynamic decision-making instead of hard-coded chains.\n","* Combine **Pipeline + Chains + Agents + Memory** for production-ready AI apps.\n","\n","---\n","\n","If you want, I can also create a **LangChain Master Coding Cheat Sheet PDF/Image** that includes **LLMs, Chains, Agents, Memory, Tools, and RAG** with **ready-to-run code snippets for all major use cases**.\n","\n","Do you want me to do that?\n"],"metadata":{"id":"H5ry5wGTXyjV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sItNY3gJXxll"},"outputs":[],"source":[]}]}